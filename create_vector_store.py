import os
from typing import Optional, List
from dotenv import load_dotenv

from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv("./.env")

class PDFVectorStore:
    """
    Class Ä‘á»ƒ táº¡o vÃ  quáº£n lÃ½ vector store tá»« file PDF
    """
    
    def __init__(self, embedding_model: str = "models/embedding-001"):
        """
        Khá»Ÿi táº¡o PDFVectorStore
        
        Args:
            embedding_model (str): TÃªn model embedding cá»§a Gemini
        """
        try:
            self.embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model)
            # print(f"âœ… Embedding model ({embedding_model}) Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!")
        except Exception as e:
            print(f"âŒ Lá»—i khi khá»Ÿi táº¡o Embedding model: {e}")
            print("ğŸ’¡ Vui lÃ²ng Ä‘áº£m báº£o báº¡n Ä‘Ã£ Ä‘áº·t biáº¿n mÃ´i trÆ°á»ng 'GOOGLE_API_KEY' vÃ  nÃ³ há»£p lá»‡.")
            raise e
    
    def load_pdf(self, pdf_path: str) -> List[Document]:
        """
        Load tÃ i liá»‡u tá»« file PDF
        
        Args:
            pdf_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file PDF
            
        Returns:
            List[Document]: Danh sÃ¡ch cÃ¡c document Ä‘Ã£ load
        """
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y file PDF: {pdf_path}")
        
        try:
            print(f"ğŸ“„ Äang táº£i tÃ i liá»‡u tá»« PDF: {pdf_path}")
            loader = PyPDFLoader(pdf_path)
            docs = loader.load()
            print(f"âœ… ÄÃ£ táº£i {len(docs)} trang tá»« PDF.")
            return docs
        except Exception as e:
            print(f"âŒ Lá»—i khi táº£i PDF: {e}")
            raise e
    
    def split_documents(
        self, 
        docs: List[Document], 
        chunk_size: int = 1000, 
        chunk_overlap: int = 150,
        add_section_metadata: bool = True
    ) -> List[Document]:
        """
        Chia tÃ i liá»‡u thÃ nh cÃ¡c chunks nhá» hÆ¡n
        
        Args:
            docs (List[Document]): Danh sÃ¡ch documents cáº§n chia
            chunk_size (int): KÃ­ch thÆ°á»›c má»—i chunk
            chunk_overlap (int): Sá»‘ kÃ½ tá»± overlap giá»¯a cÃ¡c chunks
            add_section_metadata (bool): CÃ³ thÃªm metadata section khÃ´ng
            
        Returns:
            List[Document]: Danh sÃ¡ch cÃ¡c chunks
        """
        try:
            print(f"âœ‚ï¸ Äang chia tÃ i liá»‡u thÃ nh chunks (size={chunk_size}, overlap={chunk_overlap})...")
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                length_function=len,
                separators=["\n\n", "\n", ". ", " ", ""]
            )
            
            all_splits = text_splitter.split_documents(docs)
            print(f"âœ… ÄÃ£ chia thÃ nh {len(all_splits)} chunks.")
            
            # ThÃªm metadata section náº¿u Ä‘Æ°á»£c yÃªu cáº§u
            if add_section_metadata:
                self._add_section_metadata(all_splits)
                print("âœ… ÄÃ£ thÃªm metadata 'section' cho cÃ¡c chunks.")
            
            return all_splits
        except Exception as e:
            print(f"âŒ Lá»—i khi chia documents: {e}")
            raise e
    
    def _add_section_metadata(self, documents: List[Document]):
        """
        ThÃªm metadata section (beginning, middle, end) cho documents
        
        Args:
            documents (List[Document]): Danh sÃ¡ch documents cáº§n thÃªm metadata
        """
        total_documents = len(documents)
        third = total_documents // 3
        
        for i, document in enumerate(documents):
            if i < third:
                document.metadata["section"] = "beginning"
            elif i < 2 * third:
                document.metadata["section"] = "middle"
            else:
                document.metadata["section"] = "end"
    
    def create_vector_store(self, documents: List[Document]) -> FAISS:
        """
        Táº¡o vector store tá»« danh sÃ¡ch documents
        
        Args:
            documents (List[Document]): Danh sÃ¡ch documents cáº§n index
            
        Returns:
            FAISS: Vector store Ä‘Ã£ Ä‘Æ°á»£c táº¡o
        """
        try:
            print(f"ğŸ” Äang táº¡o vector store vÃ  index {len(documents)} chunks...")
            
            # Táº¡o vector store tá»« documents
            vector_store = FAISS.from_documents(documents, self.embeddings)
            
            print(f"âœ… ÄÃ£ táº¡o vector store vÃ  index {len(documents)} chunks thÃ nh cÃ´ng!")
            return vector_store
        except Exception as e:
            print(f"âŒ Lá»—i khi táº¡o vector store: {e}")
            raise e
    
    def create_vector_store_from_pdf(
        self, 
        pdf_path: str,
        chunk_size: int = 1000,
        chunk_overlap: int = 150,
        add_section_metadata: bool = True
    ) -> FAISS:
        """
        Táº¡o vector store trá»±c tiáº¿p tá»« file PDF (hÃ m all-in-one)
        
        Args:
            pdf_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file PDF
            chunk_size (int): KÃ­ch thÆ°á»›c má»—i chunk
            chunk_overlap (int): Sá»‘ kÃ½ tá»± overlap giá»¯a cÃ¡c chunks
            add_section_metadata (bool): CÃ³ thÃªm metadata section khÃ´ng
            
        Returns:
            FAISS: Vector store Ä‘Ã£ Ä‘Æ°á»£c táº¡o vÃ  index
        """
        try:
            # 1. Load PDF
            docs = self.load_pdf(pdf_path)
            
            # 2. Split documents
            chunks = self.split_documents(
                docs, 
                chunk_size=chunk_size, 
                chunk_overlap=chunk_overlap,
                add_section_metadata=add_section_metadata
            )
            
            # 3. Create vector store
            vector_store = self.create_vector_store(chunks)
            
            print(f"ğŸ‰ HoÃ n thÃ nh! Vector store Ä‘Ã£ sáºµn sÃ ng vá»›i {len(chunks)} chunks.")
            return vector_store
            
        except Exception as e:
            print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh táº¡o vector store tá»« PDF: {e}")
            raise e
    
    def save_vector_store(self, vector_store: FAISS, save_path: str):
        """
        LÆ°u vector store vÃ o local
        
        Args:
            vector_store (FAISS): Vector store cáº§n lÆ°u
            save_path (str): ÄÆ°á»ng dáº«n thÆ° má»¥c Ä‘á»ƒ lÆ°u
        """
        try:
            print(f"ğŸ’¾ Äang lÆ°u vector store vÃ o: {save_path}")
            vector_store.save_local(save_path)
            print(f"âœ… ÄÃ£ lÆ°u vector store thÃ nh cÃ´ng!")
        except Exception as e:
            print(f"âŒ Lá»—i khi lÆ°u vector store: {e}")
            raise e
    
    def load_vector_store(self, load_path: str) -> FAISS:
        """
        Load vector store tá»« local
        
        Args:
            load_path (str): ÄÆ°á»ng dáº«n thÆ° má»¥c chá»©a vector store
            
        Returns:
            FAISS: Vector store Ä‘Ã£ Ä‘Æ°á»£c load
        """
        try:
            # print(f"ğŸ“‚ Äang load vector store tá»«: {load_path}")
            vector_store = FAISS.load_local(
                load_path, 
                self.embeddings,
                allow_dangerous_deserialization=True  # Cáº§n thiáº¿t cho FAISS
            )
            # print(f"âœ… ÄÃ£ load vector store thÃ nh cÃ´ng!")
            return vector_store
        except Exception as e:
            print(f"âŒ Lá»—i khi load vector store: {e}")
            raise e


# === HÃ€M TIá»†N ÃCH (Utility Functions) ===

def create_db_from_pdf(
    pdf_path: str,
    chunk_size: int = 1000,
    chunk_overlap: int = 150,
    embedding_model: str = "models/embedding-001",
    add_section_metadata: bool = True
) -> FAISS:
    """
    HÃ m tiá»‡n Ã­ch Ä‘á»ƒ táº¡o vector store tá»« PDF má»™t cÃ¡ch nhanh chÃ³ng
    
    Args:
        pdf_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file PDF
        chunk_size (int): KÃ­ch thÆ°á»›c má»—i chunk
        chunk_overlap (int): Sá»‘ kÃ½ tá»± overlap giá»¯a cÃ¡c chunks
        embedding_model (str): Model embedding
        add_section_metadata (bool): CÃ³ thÃªm metadata section khÃ´ng
        
    Returns:
        FAISS: Vector store Ä‘Ã£ Ä‘Æ°á»£c táº¡o
    """
    pdf_vector_store = PDFVectorStore(embedding_model=embedding_model)
    return pdf_vector_store.create_vector_store_from_pdf(
        pdf_path=pdf_path,
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        add_section_metadata=add_section_metadata
    )


def get_db_from_saved(
    load_path: str,
    embedding_model: str = "models/embedding-001"
) -> FAISS:
    """
    HÃ m tiá»‡n Ã­ch Ä‘á»ƒ load vector store Ä‘Ã£ lÆ°u
    
    Args:
        load_path (str): ÄÆ°á»ng dáº«n thÆ° má»¥c chá»©a vector store
        embedding_model (str): Model embedding
        
    Returns:
        FAISS: Vector store Ä‘Ã£ Ä‘Æ°á»£c load
    """
    pdf_vector_store = PDFVectorStore(embedding_model=embedding_model)
    return pdf_vector_store.load_vector_store(load_path)


# === DEMO ===
if __name__ == "__main__":
    pdf_vs1 = PDFVectorStore()
    doc = pdf_vs1.load_pdf("data/Data_wiki_Elon_Musk.pdf")
    doc_splits = pdf_vs1.split_documents(doc)

    print(doc_splits[0].metadata)
    # vector_store = pdf_vs1.create_vector_store(doc_splits)
    # vector_store.save_local("vector_store_faiss")


    # vector_store = pdf_vs1.create_db_from_pdf("data/Data_wiki_Elon_Musk.pdf", add_section_metadata=False)
    # vector_store.save_local("/db/vector_store_faiss")

    # print("Ä‘Ã£ táº¡o vector store vÃ  lÆ°u vÃ o local táº¡i: /db/vector_store_faiss")